import { NextResponse } from 'next/server'
import { transcribeAudio } from '@/lib/ai/whisper'
import { generateContent } from '@/lib/ai/gemini'

// API route for processing audio files
// This handles: upload -> transcription -> generation

export async function POST(request: Request) {
    try {
        const formData = await request.formData()
        const audioFile = formData.get('audio') as File | null
        const tonePreset = formData.get('tone') as string || 'standard'

        if (!audioFile) {
            return NextResponse.json(
                { error: 'No audio file provided' },
                { status: 400 }
            )
        }

        // Validate file size (30MB max)
        if (audioFile.size > 30 * 1024 * 1024) {
            return NextResponse.json(
                { error: 'ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¯30MBä»¥ä¸‹ã«ã—ã¦ãã ã•ã„' },
                { status: 400 }
            )
        }

        // Check if API keys are configured
        if (!process.env.OPENAI_API_KEY || !process.env.GOOGLE_AI_API_KEY) {
            // Return mock data if API keys not configured
            console.log('API keys not configured, returning mock data')
            return NextResponse.json({
                success: true,
                mock: true,
                data: {
                    transcript: `ã“ã‚Œã¯ã‚µãƒ³ãƒ—ãƒ«ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚

ä»Šæ—¥ã¯ã€ŒéŸ³å£°é…ä¿¡ã®é­…åŠ›ã€ã«ã¤ã„ã¦ãŠè©±ã—ã—ã¾ã™ã€‚éŸ³å£°é…ä¿¡ã¯ã€ã„ã¤ã§ã‚‚ã©ã“ã§ã‚‚éŒ²éŸ³ã§ãã‚‹æ‰‹è»½ã•ãŒé­…åŠ›ã§ã™ã€‚

é€šå‹¤ä¸­ã‚„å®¶äº‹ã‚’ã—ãªãŒã‚‰ã§ã‚‚è´ã‘ã‚‹ã®ã§ã€ãƒªã‚¹ãƒŠãƒ¼ã•ã‚“ã«ã¨ã£ã¦ã‚‚ä¾¿åˆ©ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã™ã­ã€‚`,
                    summary: 'éŸ³å£°é…ä¿¡ã®æ‰‹è»½ã•ã¨ã€ãƒªã‚¹ãƒŠãƒ¼ã«ã¨ã£ã¦ã®åˆ©ä¾¿æ€§ã«ã¤ã„ã¦è§£èª¬ã€‚ã„ã¤ã§ã‚‚ã©ã“ã§ã‚‚éŒ²éŸ³ãƒ»è¦–è´ã§ãã‚‹ç‚¹ãŒé­…åŠ›ã€‚',
                    titles: [
                        'ğŸ™ï¸ éŸ³å£°é…ä¿¡ã®é­…åŠ›ã‚’å¾¹åº•è§£èª¬ï¼å§‹ã‚æ–¹ã‹ã‚‰ç¶™ç¶šã®ã‚³ãƒ„ã¾ã§',
                        'ğŸ“» ãªãœä»Šã€éŸ³å£°é…ä¿¡ãªã®ã‹ï¼Ÿ3ã¤ã®ãƒ¡ãƒªãƒƒãƒˆ',
                        'ğŸŒŸ éŸ³å£°é…ä¿¡ã§äººç”ŸãŒå¤‰ã‚ã£ãŸè©±',
                    ],
                    description: `ã€ä»Šæ—¥ã®ãƒ†ãƒ¼ãƒã€‘
éŸ³å£°é…ä¿¡ã®é­…åŠ›ã«ã¤ã„ã¦

ã€å†…å®¹ã€‘
ãƒ»ã„ã¤ã§ã‚‚ã©ã“ã§ã‚‚éŒ²éŸ³ã§ãã‚‹æ‰‹è»½ã•
ãƒ»ãƒªã‚¹ãƒŠãƒ¼ã•ã‚“ã®ã€ŒãªãŒã‚‰è´ãã€ã«æœ€é©
ãƒ»ç¶™ç¶šã—ã‚„ã™ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å½¢å¼

ã€ã¾ã¨ã‚ã€‘
éŸ³å£°é…ä¿¡ã¯ã€é…ä¿¡è€…ã«ã‚‚ãƒªã‚¹ãƒŠãƒ¼ã«ã‚‚å„ªã—ã„ãƒ¡ãƒ‡ã‚£ã‚¢ã€‚ã¾ãšã¯æ°—è»½ã«å§‹ã‚ã¦ã¿ã¾ã—ã‚‡ã†ï¼

#standfm #éŸ³å£°é…ä¿¡ #ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ`,
                    xPost: `ğŸ™ï¸ éŸ³å£°é…ä¿¡ã®é­…åŠ›ã£ã¦ï¼Ÿ

âœ… ã„ã¤ã§ã‚‚ã©ã“ã§ã‚‚éŒ²éŸ³OK
âœ… ãªãŒã‚‰è´ãã§åŠ¹ç‡â—
âœ… ç¶šã‘ã‚„ã™ã„ï¼

éŸ³å£°ã¯è©±ã™ã ã‘ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ãªã‚‹ã€‚
ã“ã‚Œã£ã¦ã™ã”ã„ã“ã¨ã ã¨æ€ã†ã‚“ã§ã™ã€‚

#standfm #éŸ³å£°é…ä¿¡`,
                },
            })
        }

        // Step 1: Transcribe audio using Whisper
        console.log('Transcribing audio...')
        const audioBuffer = await audioFile.arrayBuffer()
        const rawTranscript = await transcribeAudio(audioBuffer, audioFile.name)

        // Step 2: Generate content using Gemini
        console.log('Generating content...')
        const generated = await generateContent(rawTranscript, tonePreset)

        return NextResponse.json({
            success: true,
            data: {
                transcript: generated.cleanedTranscript,
                summary: generated.summary,
                titles: generated.titles,
                description: generated.standfmDescription,
                xPost: generated.xPost,
            },
        })
    } catch (error) {
        console.error('Processing error:', error)
        return NextResponse.json(
            { error: error instanceof Error ? error.message : 'å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ' },
            { status: 500 }
        )
    }
}
